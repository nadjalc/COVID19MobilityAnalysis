{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(sequence): #removes duplicates from a list whilst preserving order\n",
    "    visited = set()\n",
    "    return [x for x in sequence if not (x in visited or visited.add(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(el):\n",
    "    a = el.split('.')[0]\n",
    "    b = datetime.strptime(a, fmt)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%Y-%m-%d %H:%M:%S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"output_datasets/parked_time_data_nextbike_2020-01.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url, sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parking_begin'] = df['parking_begin'].map(parse_timestamp)\n",
    "df['parking_end'] = df['parking_end'].map(parse_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns()', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns= ['old_index', 'lat', 'lng', 'parking_begin', 'parking_end', 'parked_time',\n",
    "                                'uid', 'name', 'address', 'available_bikes', 'maintenance', 'bike', 'bike_racks', 'bikes', \n",
    "                                'booked_bikes', 'free_racks', 'free_special_racks', 'number', \n",
    "                                'place_type', 'rack_locks', 'special_racks', 'spot', 'terminal_type', 'city',\n",
    "                                'country_code', 'company', 'timezone'] ) \n",
    "#empty dataframe with the new column structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLD_INDEX is gonna be used later when we itterate trough smaller data frames containing only data rows with same uid. \n",
    "#### These subset data frames create new indexes but we use old index to compare positions based on the original place in the main df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uidsToList = df['uid'].tolist()\n",
    "uidsList = unique(uidsToList) #removes duplicates from a list whilst preserving order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uidsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"index\": \"old_index\"}, inplace=True) #create duplicate column of indexes - old_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to merge all the rows with the same uid into one row\n",
    "### First we need to check GPS errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old index order is used to interupt same uid processing if two rows are not in a sequence in original data frame. This eliminates the error that was created in cases when one uid appeared for to riddes that are sepparated by many other rides on the same bike. This error is related to how the uid is generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "questionable_changes = {} #creating dictionary to hold uid:difference \n",
    "for uid in uidsList: \n",
    "    single_uid_records = df[df['uid']==uid]\n",
    "    first_row_data = single_uid_records.iloc[0]\n",
    "    last_end_time = first_row_data['parking_end']\n",
    "    last_oi = first_row_data['old_index']\n",
    "\n",
    "    for index, row in islice(single_uid_records.iterrows(), 1, None):\n",
    "        if last_oi+1 != df['old_index'][index]: #using old index to interupt same uid processing if two rows are not in a sequence in original data frame\n",
    "            break\n",
    "\n",
    "        d1_ts = time.mktime(df['parking_begin'][index].timetuple())\n",
    "        d2_ts = time.mktime(last_end_time.timetuple())\n",
    "\n",
    "        minsDiff = round((int(d1_ts-d2_ts) / 60), 0)\n",
    "\n",
    "        last_end_time = row['parking_end']\n",
    "        last_oi = df['old_index'][index]\n",
    "        if minsDiff > 1:\n",
    "            questionable_changes[uid] = minsDiff\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "questionable_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questionable_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(questionable_changes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We checked GPS errors and found multiple questionable changes, meaning that bike was missing from GPS for longer time than just an momentarily variation in location. \n",
    "#### Changes in location were controled (making distance controle for that) and conclusion is thata everything with same uid should be merged. Rows with same uid's will be merged and minutes of standing added together + difference in minutes that looks like a ride but it is only GPS error\n",
    "\n",
    "### Running cells to clean the data from extra rows (temporar solutions for distance check and for choosing lat and lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in uidsList: \n",
    "    single_uid_records = df[df['uid']==uid]\n",
    "    first_row_data = single_uid_records.iloc[0]\n",
    "    last_end_time = first_row_data['parking_end']\n",
    "    current_sum = first_row_data['parked_time']\n",
    "    last_oi = first_row_data['old_index']\n",
    "\n",
    "\n",
    "    new_df = new_df.append({'old_index': first_row_data['old_index'], 'lat' : first_row_data['lat'], 'lng' : first_row_data['lng'], \n",
    "                            'parking_begin' : first_row_data['parking_begin'],\n",
    "                            'parking_end' : last_end_time, 'parked_time' : first_row_data['parked_time'],\n",
    "                            'uid' : first_row_data['uid'], 'name' : first_row_data['name'], 'address' : first_row_data['address'],\n",
    "                            'bike' : first_row_data['bike'], 'bike_racks' : first_row_data['bike_racks'], \n",
    "                            'bikes' : first_row_data['bikes'], 'booked_bikes' : first_row_data['booked_bikes'], \n",
    "                            'free_racks' : first_row_data['free_racks'], 'free_special_racks' : first_row_data['free_special_racks'],\n",
    "                            'maintenance' : first_row_data['maintenance'], 'number' : first_row_data['number'], \n",
    "                            'place_type' : first_row_data['place_type'], 'rack_locks' : first_row_data['rack_locks'],\n",
    "                            'special_racks' : first_row_data['special_racks'], 'spot' : first_row_data['spot'], \n",
    "                            'terminal_type' : first_row_data['terminal_type'], 'city' : first_row_data['city'],\n",
    "                            'country_code' : first_row_data['country_code'], 'company' : first_row_data['company'],\n",
    "                            'timezone' : first_row_data['timezone'], 'available_bikes' : first_row_data['available_bikes']}, ignore_index=True) \n",
    "\n",
    "    for index, row in islice(single_uid_records.iterrows(), 1, None):\n",
    "        if last_oi+1 != df['old_index'][index]:\n",
    "            break\n",
    "\n",
    "        d1_ts = time.mktime(df['parking_begin'][index].timetuple())\n",
    "        d2_ts = time.mktime(last_end_time.timetuple())\n",
    "\n",
    "        minsDiff = round((int(d1_ts-d2_ts) / 60), 0)\n",
    "        current_sum += row['parked_time'] + minsDiff\n",
    "\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('parked_time')] = current_sum\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('lat')] = row['lat']\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('lng')] = row['lng']\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('parking_end')] = row['parking_end']\n",
    "\n",
    "        last_end_time = row['parking_end']\n",
    "        last_oi = df['old_index'][index]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(['old_index'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('processed_data_nextbike_2020-01.csv', sep=';', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
