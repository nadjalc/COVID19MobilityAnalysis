{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_new_row(data_frame, row):\n",
    "    data_frame = data_frame.append({'lat_begin' : row['lat'], 'lng_begin' : row['lng'],\n",
    "                                'lat_end' : 0, 'lng_end' : 0,\n",
    "                                'ride_begin' : row['parking_end'], 'ride_end' : 0,\n",
    "                                'ride_time' : 0,\n",
    "                                'uid_begin' : row['uid'], 'uid_end' : 0, 'standing_before_ride' : row['parked_time'],\n",
    "                                'name' : row['name'], 'address' : row['address'],\n",
    "                                'bike' : row['bike'], 'bike_racks' : row['bike_racks'], \n",
    "                                'bikes' : row['bikes'], 'booked_bikes' : row['booked_bikes'], \n",
    "                                'free_racks' : row['free_racks'], 'free_special_racks' : row['free_special_racks'],\n",
    "                                'maintenance' : row['maintenance'], 'number' : row['number'], \n",
    "                                'place_type' : row['place_type'], 'rack_locks' : row['rack_locks'],\n",
    "                                'special_racks' : row['special_racks'], 'spot' : row['spot'], \n",
    "                                'terminal_type' : row['terminal_type'], 'city' : row['city'],\n",
    "                                'country_code' : row['country_code'], 'company' : row['company'],\n",
    "                                'timezone' : row['timezone'],\n",
    "                                'available_bikes' : row['available_bikes']}, ignore_index=True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_timestamp(el):\n",
    "    a = el.split('.')[0]\n",
    "    b = datetime.strptime(a, fmt)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '%Y-%m-%d %H:%M:%S'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processes the data in order to create new column  'ride_time_minutes' \n",
    "\n",
    "#### As URL set one of the following:\n",
    "1. 'cleaned_data_nextbike_yy-mm.csv.gz' if you want to work with original cleaned data \n",
    "2. 'processed_data_nextbike_yy-mm.csv.gz' if you want to work with data that has GPS errors removed \n",
    "\n",
    "CHANGE NAME OF OUTPUT TO DESCRIBE THE CHOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"/bigdata/jelicicna/output_datasets/processed_data_nextbike_2019-12.csv.gz\"\n",
    "df = pd.read_csv(url, sep=';', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['parking_begin'] = df['parking_begin'].map(parse_timestamp)\n",
    "df['parking_end'] = df['parking_end'].map(parse_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"uid\"].duplicated().any() #checking if cleaning in notebook @3 was done - there should be no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame(columns= ['lat_begin', 'lng_begin', 'lat_end', 'lng_end', 'ride_begin', 'ride_end', 'ride_time', \n",
    "                                'uid_begin', 'uid_end', 'standing_before_ride', 'address', 'name', 'available_bikes', 'bike', 'bike_racks', 'bikes', \n",
    "                                'booked_bikes', 'free_racks', 'free_special_racks', 'maintenance', 'number', \n",
    "                                'place_type', 'rack_locks', 'special_racks', 'spot', 'terminal_type', 'city',\n",
    "                                'country_code', 'company', 'timezone'] ) #empty dataframe with the new column structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikesToList = df['name'].tolist()\n",
    "bikesList = list(set(bikesToList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in bikesList: #repeat for each bike/bike name\n",
    "    single_bike_records = df[df['name']==name]\n",
    "    first_row_data = single_bike_records.iloc[0]\n",
    "    last_end_time = first_row_data['parking_end']\n",
    "\n",
    "    new_df = append_new_row(new_df, first_row_data)\n",
    "\n",
    "    for index, row in islice(single_bike_records.iterrows(), 1, None):\n",
    "\n",
    "        d1_ts = time.mktime(df['parking_begin'][index].timetuple())\n",
    "        d2_ts = time.mktime(last_end_time.timetuple())\n",
    "\n",
    "        minsDiff = round((int(d1_ts-d2_ts) / 60), 0)\n",
    "\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('ride_time')] = minsDiff\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('lat_end')] = row['lat']\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('lng_end')] = row['lng']\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('ride_end')] = row['parking_begin']\n",
    "        new_df.iloc[-1, new_df.columns.get_loc('uid_end')] = row['uid']\n",
    "\n",
    "        last_end_time = row['parking_end']\n",
    "        \n",
    "        new_df = append_new_row(new_df, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Prevous code assignes 0 values to some features that should be updated trough itteration to contain acctual end values of one ride.\n",
    "### As a result for each bike there will be one extra row that has not updated values, meaning itteration has reached the end for selected bike and 0 values were not updated. \n",
    "### In the following cells we check for rows like that - idealy number of rows shoud match number of bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_df = new_df[new_df['ride_end'] == 0]\n",
    "control_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bikesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_indexes = list(control_df.index.values)\n",
    "len(incorrect_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in incorrect_indexes:\n",
    "    if i in new_df.index.values:\n",
    "        new_df.drop(i, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df['ride_time'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('/bigdata/jelicicna/output_datasets/rides_table_nextbike_2019-12.csv', sep=';', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
